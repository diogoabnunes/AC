# Exame Modelo 2022

## 1. From the broadest possible perspective, data mining approaches analyze data obtained from a phenomenon to:
- [ ] anticipate future deviations from expected behavior and explain the causes of these deviations.
- [ ] understand or anticipate future deviations from expected behavior.
- [ ] predict future behavior and explain the causes of that behavior.
- [x] understand past behavior or predict future behavior.

## 2. In general, the most important challenge in carrying out a successful data mining project is the lack of guarantees regarding the results because:
- [ ] the CRIPS-DM methodology does not guarantee that the business objectives are quantifiable.
- [ ] the volume of data is so large that it is not possible to analyze it.
- [ ] CRISP-DM methodology does not provide instruments to validate these results.
- [x] the data may not contain the information needed to achieve the business objectives.

## 3. Indicate in which of the following cases the reliability of the results of a poll on the vote intentions would be significantly affected. The poll is made on the  basis of a sample of citizens:
- [ ] with minimum age to vote, in accordance with the electoral law of Portugal.
- [ ] selected completely randomly.
- [ ] national and/or foreigners entitled to vote.
- [x] with landline.

## 4. A set of data has missing values in a numeric variable, caused by data collection errors. Which of the following techniques is best suited to fill these values:
- [ ] 0.
- [x] median.
- [ ] a value much higher than the highest observed value.
- [ ] the most frequent observed value.

## 5. In a classification problem, where the objective is to predict whether a bus will be delayed in arriving at the next stop or not, the use of the data to estimate the generalization error should be:
- [ ] use a random sample of 70% of the data for training and the rest for testing.
- [ ] use a random sample of 30% of the data for training and the rest for testing.
- [ ] given day d, use data from d+1 for training and data up to d for testing.
- [x] given day d, use data up do d-1 for training and data from d for testing.

## 6. A prediction problem can be seen as, given a phenomenon y=f(x1, x2, ..., xN), apply a learning algorithm:
- [ ] to evaluate whether the value of the function f(x1, x2, ..., xN) is really y.
- [ ] to the training data, represented as f(x1, x2, ..., xN), to try to predict the value of y.
- [x] to the training data, represented as (y, x1, x2, ..., xN), to try to identify f.
- [ ] to the training data, represented as (y, x1, x2, ..., xN), to assess whether f is really the function that determines the relationship between the target variable y and the independent variables (x1, x2, ..., xN).

## 7. In the k-means algorithm, as the value of the input parameter k increases, the sum of the within clusters quadratic errors:
- [ ] increase.
- [ ] does not change.
- [ ] may increase or decrease.
- [x] decrease.

## 8. If the rule {potatos}=>{carrots} has a support of 0.5 and confidence of 1.0 then the rule {carrots}=>{lettuce} will have a support of:
- [ ] 0.5 or higher.
- [ ] 0.5.
- [ ] less than 0.5.
- [x] this case is impossible.

## 9. One method to control overfitting in decision trees is to:
- [ ] reduce the number of levels in the tree, to minimize the probability that a leaf will have an excessive number of examples.
- [ ] increase the number of levels in the tree, to minimize the probability that a leaf will have an insufficient number of examples.
- [ ] increase the number of levels in the tree, to minimize the probability that a leaf will have an excessive number of examples.
- [x] reduce the number of levels in the tree, to minimize the probability that a leaf will have an insufficient number of examples.

## 10. The AUC measure:
- [ ] quantifies the probability that a negative example is ranked higher than a positive example.
- [ ] represents graphically the probability that a negative example is ranked higher than a positive example as the decision threshold decreases.
- [ ] represents graphically the probability that a positive example is ranked higher than a negative example as the decision threshold decreases.
- [x] quantifies the probability that a positive example is ranked higher than a negative example.

## 11. A Neural Network is a universal approximator because:
- [ ] it can model any continuous function with only 1 node in the internal layer.
- [ ] it can learn any model that any other algorithm learns, including decision trees, SVM, and Naive Bayes.
- [x] it can model any continuous function, given a sufficient number of nodes.
- [ ] it can learn any model that any other algorithm learns, including decision trees, SVM and Naive Bayes, given a sufficient number of nodes.

## 12. Metalearning can be described as:
- [ ] the development of super-algorithms that are immune to the No-Free-Lunch theorem.
- [ ] a learning approach to correct the predictions made by learning algorithms.
- [ ] the development of super-algorithms that are immune to the curse of dimensionality.
- [x] a learning approach to understand the behavior of learning algorithms.